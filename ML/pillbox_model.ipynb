{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a206321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchsummary\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51896e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델정의\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=4800, freeze_resnet=True):\n",
    "        super(ResNet50Classifier, self).__init__()\n",
    "        \n",
    "        # Resnet50 model\n",
    "        # pretrained 모델 사용\n",
    "        self.backborn = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # pretrained weight freeze 여부\n",
    "        if freeze_resnet:\n",
    "            for param in self.backborn.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # resnet50 출력채널수\n",
    "        num_features = self.backborn.fc.in_features\n",
    "        \n",
    "        # resnet50의 마지막 출력채널을 제거\n",
    "        self.backborn.fc = nn.Identity()\n",
    "        \n",
    "        # 우리가 분류할 class만큼 full connected 레이어 추가\n",
    "        num_intermediate = (num_features + num_classes) // 2\n",
    "        self.intermediate = nn.Linear(num_features, num_intermediate)\n",
    "        self.classifier = nn.Linear(num_intermediate, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backborn(x)\n",
    "        x = self.intermediate(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1887c385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5087\n"
     ]
    }
   ],
   "source": [
    "# 이미지 투명도 제거 Transform\n",
    "class RemoveAlpha:\n",
    "    def __call__(self, img):\n",
    "        img = img.convert('RGB')\n",
    "        return img\n",
    "\n",
    "# 성능을 위해 줄임\n",
    "batch_size = 64\n",
    "    \n",
    "# 데이터 로더\n",
    "base_path = \"e:\\\\pill_image_cropped\" # './sample_data'\n",
    "\n",
    "# 데이터셋 전처리 이미 되어있음\n",
    "transform = transforms.Compose([\n",
    "#     RemoveAlpha(),\n",
    "#     transforms.CenterCrop(1200),\n",
    "#     transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    # transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "image_dataset = ImageFolder(base_path, transform=transform)\n",
    "print(len(image_dataset.classes))\n",
    "\n",
    "val_size = int(len(image_dataset) * 0.2)\n",
    "train_size = len(image_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(image_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, prefetch_factor=1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, prefetch_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8861be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습함수\n",
    "def train(model, train_loader, valid_loader, criterion, optimizer, device, epochs, scheduler = None):\n",
    "    result = []\n",
    "    model.to(device)\n",
    "    # print(torchsummary.summary(model, (3, 224, 224)))\n",
    "    # epochs 만큼 반복\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # 캐시 비우기\n",
    "        torch.cuda.empty_cache()\n",
    "        # train모드\n",
    "        model.train()\n",
    "        \n",
    "        # train 정확도\n",
    "        train_loss = 0.0\n",
    "        train_accuracy = 0.0\n",
    "        train_total = 0\n",
    "        \n",
    "        # train 데이터 가져옴\n",
    "        for images, labels in tqdm(train_loader, leave=False):\n",
    "            # 장치로 보냄\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # train accuracy 계산\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            accuracy = torch.sum(pred == labels.data)\n",
    "            train_accuracy += accuracy.item()\n",
    "            train_total += labels.size(0)\n",
    "            train_loss += loss.item() * images.size(0)            \n",
    "            del images, labels\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy /= train_total\n",
    "        # validation\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "        # eval모드\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                accuracy = torch.sum(pred == labels.data)\n",
    "                \n",
    "                valid_loss += loss.item() * images.size(0)\n",
    "                valid_accuracy += accuracy.item()\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy /= len(valid_loader.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} : loss : {train_loss:.3f}, accuracy : {train_accuracy:.3f}, valid_loss : {valid_loss:.3f}, valid_accuracy : {valid_accuracy:.3f}')\n",
    "        result.append((train_loss, train_accuracy, valid_loss, valid_accuracy))\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e7b41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimjeaha\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kimjeaha\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555f21deab564d5aaff81f2e61e287ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2577 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12 : loss : 5.116, accuracy : 0.153, valid_loss : 2.037, valid_accuracy : 0.109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a6cbd1e21947f8837434dfb4306a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2577 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "model = ResNet50Classifier(num_classes=5087, freeze_resnet=False)\n",
    "# train_loader = \n",
    "# valid_loader = None\n",
    "epochs = 12\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "# epoch의 80%를 완료하면 learning rate 변경\n",
    "scheduler = StepLR(optimizer, step_size = int(epochs * 0.8), gamma=0.1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "result = train(model, train_loader, val_loader, criterion, optimizer, device, epochs, scheduler)\n",
    "\n",
    "torch.save(model, \"0513_12e_resnet50_unfreeze_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f19d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 모니터\n",
    "# nvidia-smi --query-gpu utilization.gpu,utilization.memory,memory.total,memory.free,memory.used --format=csv,noheader -lms 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1676fe69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 5.116\ttrain_accu 0.153\tval_loss 2.037 \tval_accu 0.109\n",
      "train_loss 1.159\ttrain_accu 0.674\tval_loss 0.705 \tval_accu 0.216\n",
      "train_loss 0.538\ttrain_accu 0.840\tval_loss 0.522 \tval_accu 0.173\n",
      "train_loss 0.361\ttrain_accu 0.892\tval_loss 0.459 \tval_accu 0.251\n",
      "train_loss 0.285\ttrain_accu 0.915\tval_loss 0.164 \tval_accu 0.792\n",
      "train_loss 0.211\ttrain_accu 0.936\tval_loss 0.297 \tval_accu 0.363\n",
      "train_loss 0.184\ttrain_accu 0.945\tval_loss 0.365 \tval_accu 0.598\n",
      "train_loss 0.160\ttrain_accu 0.953\tval_loss 0.155 \tval_accu 0.827\n",
      "train_loss 0.139\ttrain_accu 0.959\tval_loss 0.110 \tval_accu 0.900\n",
      "train_loss 0.025\ttrain_accu 0.992\tval_loss 0.015 \tval_accu 0.990\n",
      "train_loss 0.011\ttrain_accu 0.996\tval_loss 0.031 \tval_accu 0.990\n",
      "train_loss 0.008\ttrain_accu 0.997\tval_loss 0.005 \tval_accu 0.990\n"
     ]
    }
   ],
   "source": [
    "# 수행결과 확인\n",
    "for r in result:\n",
    "    print(f'train_loss {r[0]:.3f}\\ttrain_accu {r[1]:.3f}\\tval_loss {r[2]:.3f}\\tval_accu {r[3]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e4c483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    772 MiB |   5996 MiB | 657618 GiB | 657618 GiB |\n",
      "|       from large pool |    704 MiB |   5943 MiB | 655894 GiB | 655893 GiB |\n",
      "|       from small pool |     68 MiB |    103 MiB |   1724 GiB |   1724 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    772 MiB |   5996 MiB | 657618 GiB | 657618 GiB |\n",
      "|       from large pool |    704 MiB |   5943 MiB | 655894 GiB | 655893 GiB |\n",
      "|       from small pool |     68 MiB |    103 MiB |   1724 GiB |   1724 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 781752 KiB |   5967 MiB | 655236 GiB | 655235 GiB |\n",
      "|       from large pool | 711264 KiB |   5915 MiB | 653512 GiB | 653512 GiB |\n",
      "|       from small pool |  70488 KiB |    103 MiB |   1723 GiB |   1723 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   1430 MiB |   6760 MiB |  64762 MiB |  63332 MiB |\n",
      "|       from large pool |   1360 MiB |   6656 MiB |  64284 MiB |  62924 MiB |\n",
      "|       from small pool |     70 MiB |    104 MiB |    478 MiB |    408 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 672814 KiB |   1181 MiB | 273459 GiB | 273458 GiB |\n",
      "|       from large pool | 671638 KiB |   1178 MiB | 271366 GiB | 271366 GiB |\n",
      "|       from small pool |   1176 KiB |      4 MiB |   2092 GiB |   2092 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     654    |    1146    |   32526 K  |   32525 K  |\n",
      "|       from large pool |      78    |     170    |   15231 K  |   15231 K  |\n",
      "|       from small pool |     576    |    1028    |   17294 K  |   17294 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     654    |    1146    |   32526 K  |   32525 K  |\n",
      "|       from large pool |      78    |     170    |   15231 K  |   15231 K  |\n",
      "|       from small pool |     576    |    1028    |   17294 K  |   17294 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      70    |     158    |    1100    |    1030    |\n",
      "|       from large pool |      35    |     106    |     861    |     826    |\n",
      "|       from small pool |      35    |      52    |     239    |     204    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      88    |      88    |   12069 K  |   12069 K  |\n",
      "|       from large pool |      24    |      78    |    7379 K  |    7379 K  |\n",
      "|       from small pool |      64    |      64    |    4690 K  |    4690 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 메모리 정리\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9bb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d561871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
